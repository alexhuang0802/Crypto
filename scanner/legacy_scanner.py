# -*- coding: utf-8 -*-
"""
legacy_scanner.py (Streamlit ç‰ˆ - Spot API with fallback endpoints)
- åªåšï¼šSpot 1h K ç·š MACD èƒŒé›¢æƒæï¼ˆUSDTï¼‰
- è§£æ±ºï¼šStreamlit Cloud ç›´é€£ api.binance.com å¯èƒ½è¢« 451/403/429 æ“‹
- åšæ³•ï¼šå¤šå€‹ base endpoint å¤±æ•—è‡ªå‹•åˆ‡æ›
- è¼¸å‡ºï¼šåªé¡¯ç¤ºã€Œæœ‰å‘½ä¸­ã€å¾Œçš„æˆäº¤é‡ Top5 + Bottom5ï¼ˆæœ€å¤š 10 ç­†ï¼‰
"""

import time
import requests
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed

# ====== å›ºå®šåƒæ•¸ï¼ˆç…§ä½ åŸæœ¬å¯«æ­»ï¼‰ ======
KLINE_LIMIT   = 720
QUOTE_VOL_MIN = 5_000_000
MAX_WORKERS   = 4
EXCLUDED      = {"USDCUSDT", "USDPUSDT"}
LOOKBACK      = 40
RECENT_BARS   = 5

# ä½ è¦çš„åé¡
TOP_N = 5
BOTTOM_N = 5

# ====== å¤šå€‹ endpointï¼ˆæœƒè‡ªå‹• fallbackï¼‰ ======
BASE_CANDIDATES = [
    "https://data-api.binance.vision",
    "https://api.binance.com",
]

session = requests.Session()
session.headers.update({
    "User-Agent": "scanner/1.0",
    "Accept": "application/json",
})

def _request_json(base: str, path: str, params=None, timeout=20):
    url = f"{base}{path}"
    r = session.get(url, params=params, timeout=timeout)
    if r.status_code >= 400:
        text = (r.text or "")[:300]
        raise requests.HTTPError(f"HTTP {r.status_code} for {url} params={params} body={text}")
    return r.json()

def get_json(path: str, params=None, timeout=20, retries=2, backoff=1.2):
    """
    æœƒä¾åºå˜—è©¦ BASE_CANDIDATESï¼ŒæˆåŠŸå°±å›å‚³
    å…¨éƒ¨å¤±æ•—æ‰ raise
    """
    last_err = None
    for base in BASE_CANDIDATES:
        for i in range(retries):
            try:
                return _request_json(base, path, params=params, timeout=timeout)
            except Exception as e:
                last_err = e
                time.sleep(backoff * (i + 1))
                continue
    raise last_err

# ====== MACD ======
def get_macd(df, fast=12, slow=26, signal=9):
    ema_fast = df["Close"].ewm(span=fast, adjust=False).mean()
    ema_slow = df["Close"].ewm(span=slow, adjust=False).mean()
    macd = ema_fast - ema_slow
    sig = macd.ewm(span=signal, adjust=False).mean()
    hist = macd - sig
    return macd, sig, hist

def has_bullish_line_divergence(df, lookback=LOOKBACK, recent=RECENT_BARS):
    """
    ä½æª”èƒŒé›¢ï¼ˆåšå¤šç•™æ„ï¼‰ï¼š
    åƒ¹æ ¼å‰µæ›´ä½ Lowï¼Œä½† MACD å‰µæ›´é«˜ï¼ˆèƒŒé›¢ï¼‰
    ä¸”è¨Šè™Ÿç™¼ç”Ÿåœ¨æœ€è¿‘ recent æ ¹å…§
    """
    for i in range(lookback, len(df)):
        window = df.iloc[i - lookback:i]
        prior_idx = window["Low"].idxmin()
        if (
            df["Low"].iloc[i] < df["Low"].iloc[prior_idx]
            and df["MACD"].iloc[i] > df["MACD"].iloc[prior_idx]
        ):
            if i >= len(df) - recent:
                return True
    return False

def has_bearish_line_divergence(df, lookback=LOOKBACK, recent=RECENT_BARS):
    """
    é«˜æª”èƒŒé›¢ï¼ˆåšç©ºç•™æ„ï¼‰ï¼š
    åƒ¹æ ¼æ²’æœ‰å‰µæ›´é«˜ Highï¼ˆ<= å‰é«˜ï¼‰ï¼Œä½† MACD å‰µæ›´é«˜ï¼ˆèƒŒé›¢ï¼‰
    ä¸”è¨Šè™Ÿç™¼ç”Ÿåœ¨æœ€è¿‘ recent æ ¹å…§
    """
    for i in range(lookback, len(df)):
        window = df.iloc[i - lookback:i]
        prior_idx = window["High"].idxmax()
        if (
            df["MACD"].iloc[i] > df["MACD"].iloc[prior_idx]
            and df["High"].iloc[i] <= df["High"].iloc[prior_idx]
        ):
            if i >= len(df) - recent:
                return True
    return False

# ====== Spot symbols ======
def fetch_spot_symbols_usdt():
    ex = get_json("/api/v3/exchangeInfo", timeout=20)
    symbols = []
    for s in ex.get("symbols", []):
        if s.get("status") != "TRADING":
            continue
        if s.get("quoteAsset") != "USDT":
            continue
        sym = s.get("symbol")
        if not sym:
            continue
        if sym in EXCLUDED:
            continue
        symbols.append(sym)
    return symbols

def process_symbol(symbol: str):
    """
    å›å‚³ list[dict] æˆ– None
    dict: {Symbol, Signal, Type, Vol}
    Type: BULL / BEAR
    """
    try:
        t24 = get_json("/api/v3/ticker/24hr", {"symbol": symbol}, timeout=15)
        quote_vol = float(t24.get("quoteVolume", 0.0))
        if quote_vol < QUOTE_VOL_MIN:
            return None

        k = get_json(
            "/api/v3/klines",
            {"symbol": symbol, "interval": "1h", "limit": KLINE_LIMIT},
            timeout=25,
        )
        if not isinstance(k, list) or len(k) < 120:
            return None

        df = pd.DataFrame(
            k,
            columns=[
                "Open Time","Open","High","Low","Close","Volume",
                "Close Time","Quote Asset Volume","Number of Trades",
                "Taker Buy Base Vol","Taker Buy Quote Vol","Ignore"
            ],
        )
        df[["High","Low","Close"]] = df[["High","Low","Close"]].apply(pd.to_numeric, errors="coerce")
        df = df.dropna(subset=["High","Low","Close"]).reset_index(drop=True)

        df["MACD"], df["Signal"], df["Hist"] = get_macd(df)

        bull = has_bullish_line_divergence(df)
        bear = has_bearish_line_divergence(df)

        hits = []
        if bull:
            hits.append({"Symbol": symbol, "Signal": "ğŸŸ¢ ä½æª”èƒŒé›¢(åšå¤šç•™æ„)", "Type": "BULL", "Vol": quote_vol})
        if bear:
            hits.append({"Symbol": symbol, "Signal": "ğŸ”´ é«˜æª”èƒŒé›¢(åšç©ºç•™æ„)", "Type": "BEAR", "Vol": quote_vol})

        return hits or None

    except Exception:
        return None

def _merge_same_symbol(rows: list[dict]) -> pd.DataFrame:
    """
    åŒä¸€å€‹ Symbol è‹¥åŒæ™‚ bull/bearï¼Œåˆä½µæˆä¸€ç­†ï¼ŒSignal ä¸²èµ·ä¾†
    """
    if not rows:
        return pd.DataFrame(columns=["Symbol", "Signal", "Type", "Vol"])

    df = pd.DataFrame(rows)
    # åˆä½µ Signal / Type
    agg = df.groupby("Symbol", as_index=False).agg({
        "Signal": lambda s: " / ".join(sorted(set(map(str, s)))),
        "Type":   lambda s: ",".join(sorted(set(map(str, s)))),
        "Vol":    "max",
    })
    return agg[["Symbol", "Signal", "Type", "Vol"]]

def _pick_top_bottom(df: pd.DataFrame, top_n=TOP_N, bottom_n=BOTTOM_N) -> pd.DataFrame:
    """
    åªä¿ç•™æˆäº¤é‡ Top N + Bottom N
    """
    if df.empty:
        return df

    df2 = df.sort_values(by="Vol", ascending=False).reset_index(drop=True)

    top_df = df2.head(top_n)

    # bottom å¾å°åˆ°å¤§
    bot_df = df2.sort_values(by="Vol", ascending=True).head(bottom_n)

    # åˆä½µå¾Œå»é‡ï¼ˆé¿å… top/bottom é‡è¦†ï¼‰
    out = pd.concat([top_df, bot_df], ignore_index=True)
    out = out.drop_duplicates(subset=["Symbol"]).reset_index(drop=True)

    # æœ€å¾Œå†æŒ‰ Vol å¤§åˆ°å°çœ‹èµ·ä¾†æ›´ç›´è§€
    out = out.sort_values(by="Vol", ascending=False).reset_index(drop=True)
    return out

def run_for_streamlit() -> pd.DataFrame:
    """
    çµ¦ Streamlit å‘¼å«ï¼šå›å‚³ä¸€å€‹ DataFrame
    """
    try:
        symbols = fetch_spot_symbols_usdt()
        if not symbols:
            return pd.DataFrame([{
                "Symbol": "",
                "Signal": "âš ï¸ æ²’æŠ“åˆ°ä»»ä½• USDT äº¤æ˜“å°ï¼ˆexchangeInfo å¯èƒ½ä»è¢«æ“‹ï¼‰",
                "Type": "NO_SYMBOLS",
                "Vol": 0,
            }])

        rows = []
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
            futs = {ex.submit(process_symbol, sym): sym for sym in symbols}
            for fut in as_completed(futs):
                res = fut.result()
                if res:
                    rows.extend(res)
                time.sleep(0.01)

        # åªé¡¯ç¤ºå‘½ä¸­ï¼Œæ²’å‘½ä¸­å°±çµ¦æç¤º
        if not rows:
            return pd.DataFrame([{
                "Symbol": "",
                "Signal": "ï¼ˆæœ¬æ¬¡ç„¡å‘½ä¸­èƒŒé›¢è¨Šè™Ÿï¼‰",
                "Type": "",
                "Vol": 0,
            }])

        df = _merge_same_symbol(rows)
        df = _pick_top_bottom(df, top_n=TOP_N, bottom_n=BOTTOM_N)
        return df[["Symbol", "Signal", "Type", "Vol"]]

    except Exception as e:
        return pd.DataFrame([{
            "Symbol": "",
            "Signal": "âŒ æƒæå¤±æ•—ï¼ˆè«‹çœ‹ Type æ¬„ä½éŒ¯èª¤ï¼‰",
            "Type": str(e),
            "Vol": 0,
        }])
